# ============================================================
# ğŸ§  VoiceMemo AI - Colabç‰ˆï¼ˆå…¬é–‹ç”¨ï¼‰
# ============================================================

# ---- ã€é‡è¦ã€‘å®Ÿè¡Œå‰ã«è¨­å®šã—ã¦ãã ã•ã„ ----
MICROCMS_SERVICE_ID = "your-service-id"      # ä¾‹: "voicememo"
MICROCMS_API_KEY = "YOUR_MICROCMS_API_KEY"   # microCMSç®¡ç†ç”»é¢ã§å–å¾—
NGROK_AUTH_TOKEN = "YOUR_NGROK_AUTH_TOKEN"   # https://dashboard.ngrok.com/

# ---- ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ----
print("ğŸ“¦ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
!pip install -q flask flask-cors pyngrok transformers sentence-transformers torch soundfile librosa requests faster-whisper

# ---- ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ----
import os, torch, time, json, requests, threading
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
from pyngrok import ngrok
from faster_whisper import WhisperModel
from transformers import AutoTokenizer, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer
import warnings
warnings.filterwarnings('ignore')

print(f"ğŸ”¥ GPUåˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"ğŸ’» ãƒ‡ãƒã‚¤ã‚¹: {torch.cuda.get_device_name(0)}")

# ---- ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ----
print("\nğŸ™ï¸ Kotoba Whisper (v2.2-faster, CPUç‰ˆ) èª­ã¿è¾¼ã¿ä¸­...")
asr_model = WhisperModel("RoachLin/kotoba-whisper-v2.2-faster", device="cpu", compute_type="int8")

print("ğŸ§  rinna GPT2-small èª­ã¿è¾¼ã¿ä¸­...")
tokenizer = AutoTokenizer.from_pretrained("rinna/japanese-gpt2-small")
llm_model = AutoModelForCausalLM.from_pretrained("rinna/japanese-gpt2-small")

print("ğŸ“¥ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
embedding_model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

print("âœ… å…¨ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†")

# ============================================================
# å‡¦ç†é–¢æ•°
# ============================================================

def summarize_text(text):
    """è¦ç´„ç”Ÿæˆ"""
    prompt = f"ä»¥ä¸‹ã®æ–‡ã‚’çŸ­ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚\n{text}\nè¦ç´„ï¼š"
    inputs = tokenizer.encode(prompt, return_tensors="pt", max_length=512, truncation=True)
    
    with torch.no_grad():
        outputs = llm_model.generate(inputs, max_new_tokens=60, do_sample=True, temperature=0.7)
    
    result = tokenizer.decode(outputs[0], skip_special_tokens=True)
    summary = result.split("è¦ç´„ï¼š")[-1].strip()
    
    return summary if summary else text[:100]

def generate_tags(text):
    """ã‚¿ã‚°ç”Ÿæˆï¼ˆç°¡æ˜“ï¼‰"""
    tags = []
    if "ä¼šè­°" in text: tags.append("#ä¼šè­°")
    if "äºˆå®š" in text or "æ˜æ—¥" in text: tags.append("#äºˆå®š")
    if "TODO" in text or "ã‚„ã‚‹ã“ã¨" in text: tags.append("#TODO")
    if "ã‚¢ã‚¤ãƒ‡ã‚¢" in text: tags.append("#ã‚¢ã‚¤ãƒ‡ã‚¢")
    if not tags: tags = ["#ãƒ¡ãƒ¢"]
    return tags

def upload_to_microcms(user_id, audio_url, transcript, summary, tags, filename, embedding):
    """microCMSé€ä¿¡"""
    post_data = {
        "user_id": user_id,
        "audio_url": audio_url,
        "transcript": transcript,
        "summary": summary,
        "tags": tags,
        "processed_at": datetime.now().isoformat(),
        "audio_filename": filename,
        "duration_seconds": 0,
        "embedding_vector": json.dumps(embedding.tolist())
    }
    
    headers = {
        "X-MICROCMS-API-KEY": MICROCMS_API_KEY,
        "Content-Type": "application/json"
    }
    
    endpoint = f"https://{MICROCMS_SERVICE_ID}.microcms.io/api/v1/memos"
    print(f"ğŸ“¤ microCMSé€ä¿¡ä¸­... (User: {user_id})")
    
    try:
        res = requests.post(endpoint, headers=headers, json=post_data, timeout=30)
        
        print(f"ğŸ“¤ microCMS status: {res.status_code}")
        
        if res.status_code == 201:
            result_data = res.json()
            print(f"âœ… microCMSä¿å­˜æˆåŠŸ: {result_data.get('id')}")
            return {"success": True, "content_id": result_data.get('id')}
        else:
            print(f"âŒ microCMSä¿å­˜ã‚¨ãƒ©ãƒ¼: {res.text}")
            return {"success": False, "error": f"Status {res.status_code}"}
    except Exception as e:
        print(f"âŒ microCMSæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return {"success": False, "error": str(e)}

def process_audio_file(filepath, user_id):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†"""
    filename = os.path.basename(filepath)
    print(f"ğŸ§ éŸ³å£°å‡¦ç†é–‹å§‹: {filename} (User: {user_id})")
    
    try:
        print("ğŸ¤ æ–‡å­—èµ·ã“ã—ä¸­...")
        segments, info = asr_model.transcribe(filepath, language="ja")
        transcript = " ".join([seg.text for seg in segments])
        
        print(f"ğŸ“ æ–‡å­—èµ·ã“ã—: {transcript[:100]}...")
        
        return process_text_input(transcript, filename, user_id)
    
    except Exception as e:
        print(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

def process_text_input(text, filename, user_id):
    """ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        print(f"ğŸ’­ è¦ç´„ãƒ»ã‚¿ã‚°ç”Ÿæˆä¸­... (User: {user_id})")
        
        summary = summarize_text(text)
        tags = generate_tags(text)
        
        print(f"âœ… è¦ç´„: {summary[:50]}...")
        print(f"âœ… ã‚¿ã‚°: {tags}")
        
        embedding = embedding_model.encode(summary)
        print(f"âœ… åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†")
        
        audio_url = f"pending://{filename}"
        
        upload_result = upload_to_microcms(
            user_id, audio_url, text, summary, tags, filename, embedding
        )
        
        return {
            "success": upload_result.get("success", False),
            "content_id": upload_result.get("content_id"),
            "transcript": text,
            "summary": summary,
            "tags": tags
        }
        
    except Exception as e:
        print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

# ============================================================
# Flask API
# ============================================================

app = Flask(__name__)

CORS(app, resources={
    r"/*": {
        "origins": "*",
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"]
    }
})

@app.route("/health", methods=["GET"])
def health():
    return jsonify({"status": "ok", "models_loaded": True})

@app.route("/process", methods=["POST", "OPTIONS"])
def process():
    if request.method == "OPTIONS":
        return '', 204
    
    try:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        if "audio" in request.files:
            audio_file = request.files["audio"]
            user_id = request.form.get("user_id")
            
            if not user_id:
                return jsonify({"success": False, "error": "user_idãŒå¿…è¦ã§ã™"}), 400
            
            filename = audio_file.filename
            filepath = f"/tmp/{filename}"
            audio_file.save(filepath)
            
            print(f"\n{'='*60}")
            print(f"ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡: {filename}")
            print(f"ğŸ‘¤ User: {user_id}")
            print('='*60)
            
            result = process_audio_file(filepath, user_id)
            
            if os.path.exists(filepath):
                os.remove(filepath)
            
            return jsonify(result), 200 if result.get("success") else 500
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆ
        data = request.get_json()
        
        if not data or "user_id" not in data or "text" not in data:
            return jsonify({"success": False, "error": "user_idã¨textãŒå¿…è¦ã§ã™"}), 400
        
        user_id = data["user_id"]
        text = data["text"]
        filename = f"memo_{int(time.time())}.txt"
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå—ä¿¡ (User: {user_id})")
        print('='*60)
        
        result = process_text_input(text, filename, user_id)
        
        return jsonify(result), 200 if result.get("success") else 500
    
    except Exception as e:
        print(f"âŒ API ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)}), 500

# ============================================================
# ngrok å…¬é–‹
# ============================================================

print("\n" + "="*60)
print("ğŸŒ ngrokã§å…¬é–‹ä¸­...")
print("="*60)

ngrok.set_auth_token(NGROK_AUTH_TOKEN)

try:
    ngrok.kill()
except:
    pass

tunnel = ngrok.connect(5050)
public_url = str(tunnel.public_url)

print(f"\nâœ… å…¬é–‹URL: {public_url}")
print(f"\nNext.jsã® .env.local ã«è¿½åŠ :")
print(f"COLAB_API_URL={public_url}")
print("\n" + "="*60)

def run_server():
    app.run(host='0.0.0.0', port=5050, debug=False, use_reloader=False)

server_thread = threading.Thread(target=run_server, daemon=True)
server_thread.start()

print("\nğŸ‰ APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•å®Œäº†ï¼")
print(f"\nã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {public_url}/process")
print("âš ï¸  ã“ã®ã‚»ãƒ«ã¯å®Ÿè¡Œã—ãŸã¾ã¾ä¿æŒã—ã¦ãã ã•ã„")

try:
    while True:
        time.sleep(60)
except KeyboardInterrupt:
    print("\nğŸ›‘ ã‚µãƒ¼ãƒãƒ¼åœæ­¢")
